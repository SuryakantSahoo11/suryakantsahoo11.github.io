<!DOCTYPE HTML>

<html>
	<head>
		<title>Experiments with AI Generated Media</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="/assets/css/main.css" />
		<noscript><link rel="stylesheet" href="/assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="/index.html">Suryakant Sahoo</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
									<a href="#menu" class="menuToggle"><span>Menu</span></a>
									<div id="menu">
										<ul>
											<li><a href="/index.html">Home</a></li>
											<li><a href="/Creativity/index.html">The Right Side</a></li>
											<li><a href="/Projects/index.html">The Left Side</a></li>
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<article id="main">
						<header>
							<h2>Experiments with AI Generated Media</h2>
							<p> During a course with MIT Media labs 
							<br> held by Fluid interface Group, 
							<br> we exprimented with different GAN models 
							<br> for generating image, video and audio deepfakes </p>
						</header>
						<section class="wrapper style5">
							<div class="inner">
								
								<h4>Motivation (Why)</h4>
								<p>Enrolled into the MIT Media Lab course on <b>Experiments with AI-Generated Media</b> with enthusiasm to learn about advances in the AI world and to know more about latest on <b>Deepfake for Good</b>. 
								<br> During the 5 weeks of this awesomeness met many bright, talented and creative minds and received an assurance that there are people who love to think about anti-deciplinary topics with similar interest as mine.</p>
								
								<hr />

								<h4>Description and Reflection</h4>
								<p>We dabbled into many different concepts of AI, deep-learning, GAN models and deepfake of media. The overall goal was to have a healthy discussion about the advent of deepfake media and how to utilize it for doing good for the community. 
								<br> We were devided into learning groups to work closely with others based on geo locations. Here we had 3 facet discussion about <b>Computation, Creativity</b> and <b>Society</b>; the range of discussion was of apex quality, this in particular was very interesting for me. </p>
								
								<p>Here, I would be describing very briefly about the topics we went through and the results that I generated during my learning.</p>
                                
								<h4>Style Transfer</h4>
								<p> This model peeked my interest into the potential of GAN into the art world. Style transfer model uses the style of one picture and tries to replicate similar features to the target picture. This in itself is so unique that now anyone with even a little spark of imagination can ignite result outputs that are of very high standards. 
								<br> I did a lot of experiments with many different pictures and styles, transfering <b>Lovecraftian Style</b> to <b>Rainbow Dougnuts</b> was lot of fun. I further imagined how to make this style transfer more synbolic in nature, so I transferred picture with <b>Atom's Style</b> to <b>Albert Einstien</b> sort of trying to merge physics with physist. 
								<br> Also experimented with <b>Season Change</b> by using style transfer model.</p>
                                <div class="row gtr-50 gtr-uniform">
									<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/LoveCraftian Dougnut.png" alt="" /></span></div>
									<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/SeasonSwitch.gif" alt="" /></span></div>
									<div class="col-8"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Albart Phynstien.jpg" alt="" /></span></div>
								</div>
								<br><span class="image right"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/DeepWithin.jpeg" alt="" /></span>
								<br>
								<h4>Deep Dream</h4>
								<p>The trippy algotithm, Deep dream uses an <b>activation-atlas</b>, this concept was very intriguing, made me think that what if we save the <b>Genome data</b> in a similar manner and then access that using an AI to get various combinations and see if we are able to artificaially create similar features to that of a real person. This would be something that I would love to research more on. But for now, I created a trippy staircase leading deep within. </p>
								<br>
								
								<span class="image right"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/PirateSwap.jpg" alt="" /></span>
								<h4>Neural Doodle</h4>
								<p>This particular model sparked my imagination and I thought what if I try to use this to do a face swap ? Tried out this will some of my favorite <b>'One Piece' anime charaters</b> Zoro and Luffy. 
								<br> The model did take it's sweet time (52 minutes!) to give this output result, which made me think on one of the limitation of AI, the immense <b>processing power</b> needed. Hope we soon see a day when we would be able to do these kind of tweekings in seconds facilitating realtime Neural Doodling. 
								<br> Another interesting observation was that the matplot function created a <b>rainbow like effect</b> while plotting the new image based on the provided masks. This is poweful tool that can help build scenes based on simple masks like images and then later filled in by an AI to conplete the scene! </p> 
								<br>
								<h4>Big GAN</h4>
								<p>BigGAN is trained on <b>ImageNet</b> and is helpful for getting a better sense of the Fidelity-Diversity trade off. <b>Fidelity</b> refers to image quality, whereas <b>Diversity</b> means its ability to create a variety of images. We are able to choose different categories, control the number of images generated, truncation and noise seed to compare the various result. Noticed that the generation of the faces and texts that are far away was not very clear. Guessing it's difficult or needs more training to generate smooth and detailed pictures. 
								<br> I also experimented with <b>Interpolation</b> of these images, converting one image to another : For example, I odered a Chicken Burrito from the AI Kitchen (Chicken picture to be converted to Burrito picture) The result was hilarious. The AI jumped from different steps to reach till the generation of Burrito image. I wonder what <b>Gordon Ramsay</b> has to say about this? </p>
								<div class="row gtr-50 gtr-uniform">
									<div class="col-12"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Not so chicken burrito.png" alt="Not So Chicken Burrito" /></span></div>
								</div>
								<br>
								<br>
								<h4>Cycle GAN</h4>
								<p>CycleGAN trains and learns the feature of a particular subject and then can use that on any other image, cyclically goes from domain A to B and B to A. Here we used <b>horse 2 zebra</b> converter model. But normaly, I didn't use the simple conversion, rater converted a Yak to <b>Zebryak</b> and tweeked a bit into <b>fasion</b> world.
								<br> Noticed, that this model understands specific colors and then creates zebra like stripes on them, as during my experiment with a <b>horse outline</b>, it didn't recognize the shape.
								<div class="row gtr-50 gtr-uniform">
									<div class="col-4"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Zebryak.png" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Stripshirt.png" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/horse_outline.png" alt="" /></span></div>
								</div>
								<br>
								<br>
								<h4>Progressive Growing GAN</h4>
								<p><span class="image left"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/faceshift_ProgGAN2_gif.gif" alt="" /></span> ProgGAN is more <b>human face</b> specific generation, here again we learned about the <b>Fidelity-Diversity trade off</b>. When you increase the <b>Noise</b> clearly we get more diversity and less fidelity. Here is a compiled gif of all the different faces that were created while interpolating between two AI generated female faces.</p>
								<br>
								
								<h4>NVidia Imaginaire</h4>
								<p>NVidia has released generative algorithms with pre-trained models for deepfake creation and beyond. This was super fun to work on! I was not able to tweek the <b>Face Re-enactment</b> trained model so I used photoshop to change the face in the original image, used the very dynamic <b>Trevor Noah's</b> photograph and faked face movements from another video. The resutls were good, but were not accurate. I considered this as an entry point to video deepfakes that we were about to dive in next. </p>
								<div class="row gtr-50 gtr-uniform">
									<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/tevorFake.gif" alt="" /></span></div>
								</div>
								<br>
								<br>
								<h4>First Order Motion Model</h4>
								<p> Here we created deepfakes based on work by <b>Aliaksandr Siarohin</b> by applying the motion from a video to an image. It kept me fascinated and I have described more about this in another project page <b><a href="/Projects/LaughingOldMan.html">Laughing Old Man</a></b>.
								<br> The concept behind this is called <b>Transfer Learning</b>. Transfer learning and domain adaptation refer to the situation where what has been learned in one setting is exploited to improve generalization in another setting. Meaning, we can extract facial expressions from a video and apply them to photographs. Can make a body (in an image) move by capturing motion of another similar body (in a video).
								<br> Below are the results that I produced, realised that this was an extremely powerful method that can be used by animators to be prolific.
								<br> Here, we have <b>Captain Levi</b> from the anime <b>'Attack on the Titans'</b> being out of charater. And a very <b>Buzzed Lightyear</b>, mimicing the motion of a stickman figure.    
								<div class="row gtr-50 gtr-uniform">
									<div class="col-6"><span class="image fit"><iframe width="100%" height="300" src="https://www.youtube.com/embed/MTTIXjiG27Q" title="Captain Jolly Levi" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></span></div>
									<div class="col-6"><span class="image fit"><iframe width="100%" height="300" src="https://www.youtube.com/embed/a2GUvxfwHoY" title="Very Buzzed Lightyear" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></span></div>
								</div>
								<br>
								<br>
								<h4>Audio Deepfakes</h4>
								<p> Lastly moving to Audio deepfakes, here we experimented with <b>Voice cloning</b> model to create synthetic voice. I tested the lack of diversity and made a voice clone speaking in <b>Hindi</b> the AI clearly had an <b>English Accent</b> suggesting that the training data is not compatible in adapting to diverse languages. 
								<br> This gave me an idea of having an interface AI like a <b><a href="/Projects/DirectorGAN_Concept.html">DirectorGAN</a></b> that will first understand which accent and language needs to used to synthesize the deepfake voice. Here, I made the 'Angrez' AI speak in hindi and say 'hey you, why are you looking at me like that? don't you have manners?'
								<br><audio controls>
									<source src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/AI_TameezNahiHai.wav" type="audio/wav">
								</audio>
								
								<br> Also, using <b>Mellotron</b> model I created my very own <b>Batman Voice</b> cautioning to 'Be carefull what you say on record, you never know how it will be used'. Further made the AI sing a famous <b>Linkin Park song 'Numb'</b> :D </p>
								<audio controls>
									<source src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/onRecord_Batman_sury.wav" type="audio/wav">
								</audio>
								<audio controls>
									<source src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/SingingMessageAI_NumbLP.wav" type="audio/wav">
								</audio>
								<hr />
                                
								<h4>Certificate</h4>
								<p \>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/AI-Generated Media Certificate.jpg" alt="Suryakant Sahoo Contextual master published story" /></span></div>
									</div>
								<hr \>
								<h4>Tools & Technology</h4>
									<div class="row gtr-50 gtr-uniform">
                                        <div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/mediaLab_logo.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/images/Python.jpg" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/Google Collab logo.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/Github_logo.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/photoshop logo png.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/images/linux.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/deepfake_logo.jpg" alt="" /></span></div>
                                    </div>
								
								<hr \>
								<h4>Creators</h4>
								<p>Suryakant Sahoo</p>
                        </section>
					</article>

				<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
						<li><a href="https://www.facebook.com/sahoography" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						<li><a href="https://www.instagram.com/sahoography" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="https://www.linkedin.com/in/suryakantsahoo11" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
						<li><a href="mailto:sahoography@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Suryakant Sahoo</li><li>Design: <a href="https://www.instagram.com/sahoography/?hl=en">sahoography</a></li>
					</ul>
				</footer>

			</div>

		<!-- Scripts -->
			<script src="/assets/js/jquery.min.js"></script>
			<script src="/assets/js/jquery.scrollex.min.js"></script>
			<script src="/assets/js/jquery.scrolly.min.js"></script>
			<script src="/assets/js/browser.min.js"></script>
			<script src="/assets/js/breakpoints.min.js"></script>
			<script src="/assets/js/util.js"></script>
			<script src="/assets/js/main.js"></script>

	</body>
</html>