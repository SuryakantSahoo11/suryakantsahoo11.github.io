<!DOCTYPE HTML>

<html>
	<head>
		<title>Experiments with AI Generated Media</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="/assets/css/main.css" />
		<noscript><link rel="stylesheet" href="/assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="/index.html">Suryakant Sahoo</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
									<a href="#menu" class="menuToggle"><span>Menu</span></a>
									<div id="menu">
										<ul>
											<li><a href="/index.html">Home</a></li>
											<li><a href="/Creativity/index.html">The Right Side</a></li>
											<li><a href="/Projects/index.html">The Left Side</a></li>
											<hr />
										</ul>
										<ul>	
											<li><a href="/Projects/Cooper_AirPen.html">Cooper & Airpen</a></li>
											<li><a href="/Projects/APM_Tranformation_BFSI.html">APM Transformation</a></li>
											<li><a href="/Projects/RoboCrane.html">RoboCrane</a></li>
											<li><a href="/Projects/ExperimentsWithAIGeneratedMedia.html">Experiments with AI-Generated Media</a></li>
											<li><a href="/Projects/VoiceControlRobotArm.html">Voice Controlled Robot Arm</a></li>
											<li><a href="/Projects/TouchlessGUI.html">Touchless GUI</a></li>
											<li><a href="/Projects/LaughingOldMan.html">Laughing Old Man</a></li>
											<li><a href="/Projects/MachineFirstOperations.html">Machine First Operations</a></li>
											<li><a href="/Projects/SmartNetwork.html">Smart Network</a></li>
											<li><a href="/Projects/PhyAi_Concept.html">PhyAi Concept</a></li>
											<li><a href="/Projects/DirectorGAN_Concept.html">Director GAN Concept</a></li>
											<li><a href="/Projects/VulnerabilityBasedAutomaticSoftwareUpgrade.html">Vulnerability based Automatic Software Upgrade</a></li>
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<article id="main">
						<header>
							<h2>Experiments with AI Generated Media</h2>
							<p> During a course with MIT Media labs 
							<br> held by Fluid interface Group, 
							<br> we experimented with different GAN models 
							<br> for generating image, video, and audio deepfakes </p>
						</header>
						<section class="wrapper style5">
							<div class="inner">
								
								<h4>Motivation (Why)</h4>
								<p>Enrolled in the MIT Media Lab course on <b>Experiments with AI-Generated Media</b> with enthusiasm to learn about advances in the AI world and to know more about the latest on <b>Deepfake for Good</b>. 
								<br> During the 5 weeks of this awesomeness met many bright, talented, and creative minds and received an assurance that there are people who love to think about anti-disciplinary topics of similar interests as mine.</p>
								
								<hr />

								<h4>Description and Reflection</h4>
								<p>We dabbled into many different concepts of AI, deep-learning, GAN models, and deepfake of media. The overall goal was to have a healthy discussion about the advent of deepfake media and how to utilize it for doing good for the community. 
								<br> We were divided into learning groups to work closely with others based on geo locations. Here we had 3 facet discussions about <b>Computation, Creativity</b>, and <b>Society</b>; the range of discussion was of apex quality, this, in particular, was very interesting for me. </p>
								
								<p>Here, I would be describing very briefly the topics we went through and the results that I generated during my learning.</p>
                                
								<h4>Style Transfer</h4>
								<p> This model piqued my interest in the potential of GAN in the art world. The Style Transfer model uses the style of one picture and tries to replicate similar features to the target picture. This in itself is so unique that now anyone with even a little spark of imagination can ignite result outputs that are of very high standards. 
								<br> I did a lot of experiments with many different pictures and styles, transferring <b>Lovecraftian Style</b> to <b>Rainbow Doughnuts</b> was a lot of fun. I further imagined how to make this style transfer more symbolic, so I transferred a picture with <b>Atom's Style</b> to <b>Albert Einstein</b> sort of trying to merge physics with the physicist. 
								<br> Also experimented with <b>Season Change</b> by using the style transfer model.</p>
                                <div class="row gtr-50 gtr-uniform">
									<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/LoveCraftian Dougnut.png" alt="" /></span></div>
									<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/SeasonSwitch.gif" alt="" /></span></div>
									<div class="col-8"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Albart Phynstien.jpg" alt="" /></span></div>
								</div>
								<br><span class="image right"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/DeepWithin.jpeg" alt="" /></span>
								<br>
								<h4>Deep Dream</h4>
								<p>The trippy algorithm, Deep dream uses an <b>activation-atlas</b>, this concept was very intriguing, made me think that what if we similarly save the <b>Genome data</b> and then access that using an AI to get various combinations and see if we are able to artificially create similar features to that of a real person. This would be something that I would love to research more on. But for now, I created a trippy staircase leading deep within. </p>
								<br>
								
								<span class="image right"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/PirateSwap.jpg" alt="" /></span>
								<h4>Neural Doodle</h4>
								<p>This particular model sparked my imagination and I thought what if I try to use this to do a face swap ? Tried out this will some of my favorite <b>'One Piece' anime characters</b> Zoro and Luffy. 
								<br> The model did take its sweet time (52 minutes!) to give this output result, which made me think about one of the limitations of AI, the immense <b>processing power</b> needed. Hope we soon see a day when we would be able to do these kinds of tweaking in seconds facilitating real-time Neural Doodling. 
								<br> Another interesting observation was that the matplot function created a <b>rainbow-like effect</b> while plotting the new image based on the provided masks. This is a powerful tool that can help build scenes based on simple masks like images and then later filled in by an AI to complete the scene! </p> 
								<br>
								<h4>Big GAN</h4>
								<p>BigGAN is trained on <b>ImageNet</b> and helps get a better sense of the Fidelity-Diversity trade-off. <b>Fidelity</b> refers to image quality, whereas <b>Diversity</b> means its ability to create a variety of images. We are able to choose different categories, control the number of images generated, truncation, and noise seed to compare the various result. Noticed that the generation of faces and texts that are far away was not very clear. Guessing it's difficult or needs more training to generate smooth and detailed pictures. 
								<br> I also experimented with <b>Interpolation</b> of these images, converting one image to another : For example, I ordered a Chicken Burrito from the AI Kitchen (Chicken picture to be converted to Burrito picture) The result was hilarious. The AI jumped from different steps to reach the generation of Burrito image. I wonder what <b>Gordon Ramsay</b> has to say about this? </p>
								<div class="row gtr-50 gtr-uniform">
									<div class="col-12"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Not so chicken burrito.png" alt="Not So Chicken Burrito" /></span></div>
								</div>
								<br>
								<br>
								<h4>Cycle GAN</h4>
								<p>CycleGAN trains and learns the feature of a particular subject and then can use that on any other image, cyclically going from domain A to B and B to A. Here we used the <b>horse 2 zebra</b> converter model. But normally, I didn't use the simple conversion, rater converted a Yak to <b>Zebryak</b> and tweaked a bit into the <b>fashion</b> world.
								<br> Noticed, that this model understands specific colors and then creates zebra-like stripes on them, as during my experiment with a <b>horse outline</b>, it didn't recognize the shape.
								<div class="row gtr-50 gtr-uniform">
									<div class="col-4"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Zebryak.png" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/Stripshirt.png" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/horse_outline.png" alt="" /></span></div>
								</div>
								<br>
								<br>
								<h4>Progressive Growing GAN</h4>
								<p><span class="image left"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/faceshift_ProgGAN2_gif.gif" alt="" /></span> ProgGAN is a more <b>human face-specific</b> generation, here again, we learned about the <b>Fidelity-Diversity trade-off</b>. When you increase the <b>Noise</b>, clearly we get more diversity and less fidelity. Here is a compiled GIF of all the different faces that were created while interpolating between two AI-generated female faces.</p>
								<br>
								
								<h4>NVidia Imaginaire</h4>
								<p>NVidia has released generative algorithms with pre-trained models for deepfake creation and beyond. This was super fun to work on! I was not able to tweak the <b>Face Re-enactment</b> trained model so I used photoshop to change the face in the original image, used the very dynamic <b>Trevor Noah's</b> photograph, and faked face movements from another video. The results were good but were not accurate. I considered this as an entry point to video deepfakes that we were about to dive in next. </p>
								<div class="row gtr-50 gtr-uniform">
									<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/tevorFake.gif" alt="" /></span></div>
								</div>
								<br>
								<br>
								<h4>First Order Motion Model</h4>
								<p> Here we created deepfakes based on work by <b>Aliaksandr Siarohin</b> by applying the motion from a video to an image. It kept me fascinated and I have described more about this on another project page <b><a href="/Projects/LaughingOldMan.html">Laughing Old Man</a></b>.
								<br> The concept behind this is called <b>Transfer Learning</b>. Transfer learning and domain adaptation refer to the situation where what has been learned in one setting is exploited to improve generalization in another setting. Meaning, we can extract facial expressions from a video and apply them to photographs. Can make a body (in an image) move by capturing the motion of another similar body (in a video).
								<br> Below are the results that I produced, realized that this was an extremely powerful method that can be used by animators to be prolific.
								<br> Here, we have <b>Captain Levi</b> from the anime <b>'Attack on the Titans'</b> being out of character. And a very <b>Buzzed Lightyear</b>, mimicking the motion of a stickman figure.    
								<div class="row gtr-50 gtr-uniform">
									<div class="col-6"><span class="image fit"><iframe width="100%" height="300" src="https://www.youtube.com/embed/MTTIXjiG27Q" title="Captain Jolly Levi" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></span></div>
									<div class="col-6"><span class="image fit"><iframe width="100%" height="300" src="https://www.youtube.com/embed/a2GUvxfwHoY" title="Very Buzzed Lightyear" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></span></div>
								</div>
								<br>
								<br>
								<h4>Audio Deepfakes</h4>
								<p> Lastly moving to Audio deepfakes, here we experimented with the <b>Voice cloning</b> model to create a synthetic voice. I tested the lack of diversity and made a voice clone speaking in <b>Hindi</b> the AI clearly had an <b>English Accent</b> suggesting that the training data is not compatible in adapting to diverse languages. 
								<br> This gave me an idea of having an interface AI like a <b><a href="/Projects/DirectorGAN_Concept.html">DirectorGAN</a></b> that will first understand which accent and language needs to be used to synthesize the deepfake voice. Here, I made the 'Angrez' AI speak in Hindi and say 'hey you, why are you looking at me like that? don't you have manners?'
								<br><audio controls>
									<source src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/AI_TameezNahiHai.wav" type="audio/wav">
								</audio>
								
								<br> Also, using the <b>Mellotron</b> model I created my very own <b>Batman Voice</b> cautioning to 'Be careful what you say on record, you never know how it will be used'. Further, made the AI sing a famous <b>Linkin Park song 'Numb'</b> </p>
								<audio controls>
									<source src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/onRecord_Batman_sury.wav" type="audio/wav">
								</audio>
								<audio controls>
									<source src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/SingingMessageAI_NumbLP.wav" type="audio/wav">
								</audio>
								<hr />
                                
								<h4>Future Applications</h4>
								<p>Generative AI is an immensely powerful tool and can have multi-facet benefits. Let me divide this into multiple realms, most of which may be completely fictional. I am going to wander way off the boundaries of media.</p>
								
								<h4>Scientific & Technological Realm</h4>
								<p><b>Generated chip architecture</b> – Using the various currently available chips and their performance parameters, an AI can generate architectures that will maintain the performance while optimizing power consumption
								<br>
								<br><b>What if gene</b> – Won’t it be fascinating to know which other species could have survived or might have been on this earth, maybe there were humans with blue skin and orange eyes, or maybe get dodo back to this planet? While trying to find these mysteries we might observe something very peculiar that may not be humanly possible to discover.</p>
								<h4>The realm of Social & Emotional Wellbeing</h4>
								<p><b>Deep Help</b> – Mostly targeted to the autism spectrum, people with dyslexia, and similar learning disabilities, this AI will try to generate sounds and visuals to help soothe them as well as assist them to adapt to the current structure and system around them. This can also be used for comforting and offering to counsel to anxious people and people with self-harming tendencies.
								<br>
								<br><b>MemoirAI</b> – To help people with PTSD and loss of death, this AI will use the past data and figuratively transport them to a safe place deep in nostalgia, with a person who they had always relied upon but is not around anymore.
								<br>
								<br><b>Deep Culture</b> – Embracing different cultures and languages, create a spectrum instead of trying to create a singular parameter. This AI will also help in effective education and spreading the understanding of diversity and the existence of variety (this is of utmost importance!)</p>
								<h4>Creative, Imaginative & Conceptual Realm</h4>
								<p><b>Deep Consciousness</b> – Can make AI aware of what it is doing? Aware of its latent space? What is it trying to achieve and perhaps why is it trying to achieve that? This is my long innate desire that we could invoke the same thoughts into an AI. Maybe we will in that journey, understand why we choose what we choose, why do we fearsome things but love others. We may discover the key to transferring consciousness to a distant artificial generated body, teleporting in a way, and living (being conscious) endlessly.</p>
								<hr />
								<h4>Certificate</h4>
								<p \>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-6"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/AI-Generated Media Certificate.jpg" alt="Suryakant Sahoo Contextual master published story" /></span></div>
									</div>
								<hr \>
								<h4>Tools & Technology</h4>
									<div class="row gtr-50 gtr-uniform">
                                        <div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/mediaLab_logo.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/images/Python.jpg" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/Google Collab logo.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/Github_logo.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/ExperimentsWithAIGeneratedMedia/photoshop logo png.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/images/linux.png" alt="" /></span></div>
										<div class="col-1"><span class="image fit"><img src="/Projects/images/gallery/Project_pics/LaughingOldMan/deepfake_logo.jpg" alt="" /></span></div>
                                    </div>
								
								<hr \>
								<h4>Creators</h4>
								<p>Suryakant Sahoo</p>
                        </section>
					</article>

				<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
						<li><a href="https://www.facebook.com/sahoography" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						<li><a href="https://www.instagram.com/sahoography" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="https://www.linkedin.com/in/suryakantsahoo11" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
						<li><a href="mailto:sahoography@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Suryakant Sahoo</li><li>Design: <a href="https://www.instagram.com/sahoography/?hl=en">sahoography</a></li>
					</ul>
				</footer>

			</div>

		<!-- Scripts -->
			<script src="/assets/js/jquery.min.js"></script>
			<script src="/assets/js/jquery.scrollex.min.js"></script>
			<script src="/assets/js/jquery.scrolly.min.js"></script>
			<script src="/assets/js/browser.min.js"></script>
			<script src="/assets/js/breakpoints.min.js"></script>
			<script src="/assets/js/util.js"></script>
			<script src="/assets/js/main.js"></script>

	</body>
</html>